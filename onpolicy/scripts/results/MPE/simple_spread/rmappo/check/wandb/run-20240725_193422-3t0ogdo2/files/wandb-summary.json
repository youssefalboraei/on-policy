{"value_loss": 0.011701527703553437, "policy_loss": -0.00946032631769773, "dist_entropy": 0.4030007988214493, "actor_grad_norm": 0.21744421124458313, "critic_grad_norm": 0.035322584211826324, "ratio": 0.9996781349182129, "average_episode_rewards": -114.93693590164185, "agent0/individual_rewards": -1.2289578605481868, "agent1/individual_rewards": -1.2523953605481868, "agent2/individual_rewards": -1.2211453605481868, "_runtime": 9691, "_timestamp": 1721942153, "_step": 15043200}